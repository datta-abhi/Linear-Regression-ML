{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4603b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a665f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = datasets.load_breast_cancer().data,columns = datasets.load_breast_cancer().feature_names)\n",
    "df['target'] = datasets.load_breast_cancer().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78d986c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40162fb2",
   "metadata": {},
   "source": [
    "## Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0822cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(398,)\n",
      "(171, 30)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=28)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c55f3",
   "metadata": {},
   "source": [
    "## Model Training using l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a863ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.1\n",
      "\n",
      "Train accuracy: 0.9547738693467337\n",
      "\n",
      "Test accuracy: 0.9239766081871345\n",
      "--------------------------------------------------\n",
      "C =  1\n",
      "\n",
      "Train accuracy: 0.9547738693467337\n",
      "\n",
      "Test accuracy: 0.9473684210526315\n",
      "--------------------------------------------------\n",
      "C =  10\n",
      "\n",
      "Train accuracy: 0.9623115577889447\n",
      "\n",
      "Test accuracy: 0.9532163742690059\n",
      "--------------------------------------------------\n",
      "C =  100\n",
      "\n",
      "Train accuracy: 0.9673366834170855\n",
      "\n",
      "Test accuracy: 0.9532163742690059\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhid\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abhid\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abhid\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abhid\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "for c in [0.1,1,10,100]:\n",
    "    \n",
    "    logreg = LogisticRegression(penalty='l2',max_iter=200,C = c)\n",
    "    logreg.fit(X_train,y_train)\n",
    "    \n",
    "    print('C = ',c)\n",
    "    print()\n",
    "    \n",
    "    y_pred_train = logreg.predict(X_train)\n",
    "    y_pred_test = logreg.predict(X_test)\n",
    "    \n",
    "    print('Train accuracy:',accuracy_score(y_train,y_pred_train))\n",
    "\n",
    "    print()\n",
    "    print('Test accuracy:',accuracy_score(y_test,y_pred_test))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417b381",
   "metadata": {},
   "source": [
    "## Model Training using l1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c21c92c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.1\n",
      "\n",
      "Train accuracy: 0.9422110552763819\n",
      "\n",
      "Test accuracy: 0.9298245614035088\n",
      "--------------------------------------------------\n",
      "C =  1\n",
      "\n",
      "Train accuracy: 0.9547738693467337\n",
      "\n",
      "Test accuracy: 0.9415204678362573\n",
      "--------------------------------------------------\n",
      "C =  10\n",
      "\n",
      "Train accuracy: 0.9899497487437185\n",
      "\n",
      "Test accuracy: 0.9473684210526315\n",
      "--------------------------------------------------\n",
      "C =  100\n",
      "\n",
      "Train accuracy: 0.992462311557789\n",
      "\n",
      "Test accuracy: 0.9415204678362573\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "for c in [0.1,1,10,100]:\n",
    "    \n",
    "    logreg = LogisticRegression(penalty='l1',max_iter=200,solver= 'liblinear',C = c)\n",
    "    logreg.fit(X_train,y_train)\n",
    "    \n",
    "    print('C = ',c)\n",
    "    print()\n",
    "    \n",
    "    y_pred_train = logreg.predict(X_train)\n",
    "    y_pred_test = logreg.predict(X_test)\n",
    "    \n",
    "    print('Train accuracy:',accuracy_score(y_train,y_pred_train))\n",
    "\n",
    "    print()\n",
    "    print('Test accuracy:',accuracy_score(y_test,y_pred_test))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f352e",
   "metadata": {},
   "source": [
    "### Since C is inverse to regularization strength, C = 0.1 is most regularized,  and least difference between train and test performance, ie least overfitting ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2328a2",
   "metadata": {},
   "source": [
    "### C = 100, ie least regularized, and hence we see most overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a1329",
   "metadata": {},
   "source": [
    "## Feature Selection using l1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34f44132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.01\n",
      "\n",
      "Model coeffecients:  [[ 0.      0.      0.1581  0.0036  0.      0.      0.      0.      0.\n",
      "   0.      0.      0.      0.     -0.022   0.      0.      0.      0.\n",
      "   0.      0.      0.      0.      0.     -0.0197  0.      0.      0.\n",
      "   0.      0.      0.    ]]\n",
      "\n",
      "Eliminated features:  Index(['mean radius', 'mean texture', 'mean smoothness', 'mean compactness',\n",
      "       'mean concavity', 'mean concave points', 'mean symmetry',\n",
      "       'mean fractal dimension', 'radius error', 'texture error',\n",
      "       'perimeter error', 'smoothness error', 'compactness error',\n",
      "       'concavity error', 'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst smoothness', 'worst compactness',\n",
      "       'worst concavity', 'worst concave points', 'worst symmetry',\n",
      "       'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "Total 26 features eliminated\n",
      "---------------------------------------------------------------------------\n",
      "C= 1\n",
      "\n",
      "Model coeffecients:  [[ 3.1701  0.2468 -0.078  -0.0213  0.      0.      0.      0.      0.\n",
      "   0.      0.      1.1737  0.     -0.1123  0.      0.      0.      0.\n",
      "   0.      0.      0.     -0.4218 -0.0167 -0.0158  0.     -0.1112 -4.2748\n",
      "   0.      0.      0.    ]]\n",
      "\n",
      "Eliminated features:  Index(['mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'perimeter error', 'smoothness error',\n",
      "       'compactness error', 'concavity error', 'concave points error',\n",
      "       'symmetry error', 'fractal dimension error', 'worst radius',\n",
      "       'worst smoothness', 'worst concave points', 'worst symmetry',\n",
      "       'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "Total 19 features eliminated\n",
      "---------------------------------------------------------------------------\n",
      "C= 100\n",
      "\n",
      "Model coeffecients:  [[ 1.260600e+00  3.925000e-01  1.582000e-01 -5.000000e-02  0.000000e+00\n",
      "   8.050770e+01 -3.330660e+01  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "  -6.198400e+00  2.950400e+00  2.346000e-01 -4.857000e-01  0.000000e+00\n",
      "   1.793110e+01  1.130735e+02  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "   1.290300e+00 -8.649000e-01  4.202000e-01 -3.070000e-02 -2.398330e+01\n",
      "   2.451100e+00 -2.137170e+01 -1.026599e+02 -2.986260e+01  0.000000e+00]]\n",
      "\n",
      "Eliminated features:  Index(['mean smoothness', 'mean concave points', 'mean symmetry',\n",
      "       'mean fractal dimension', 'smoothness error', 'concave points error',\n",
      "       'symmetry error', 'fractal dimension error', 'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "Total 9 features eliminated\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01,1,100]:\n",
    "    print(\"C=\",c)\n",
    "    print()\n",
    "    logreg = LogisticRegression(penalty='l1',max_iter=200,solver= 'liblinear',C = c,random_state=23)\n",
    "    logreg.fit(X_train,y_train)\n",
    "    coeffecients = np.round(logreg.coef_,4)\n",
    "    print(\"Model coeffecients: \",coeffecients)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    eliminated_features = X_train.columns[coeffecients[0]==0]\n",
    "    print('Eliminated features: ',eliminated_features)\n",
    "    print('Total {} features eliminated'.format(len(eliminated_features)))\n",
    "    print('-'*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d26acc",
   "metadata": {},
   "source": [
    "### So, as we increase strength of regularization ie reduce C, more features get eliminated by l1 (lasso) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89337649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
